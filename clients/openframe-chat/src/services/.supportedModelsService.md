<!-- source-hash: 2366ee5b59daa8592a4dace21a8473fd -->
Service for managing and caching supported AI models from multiple providers (Anthropic, OpenAI, Google Gemini). Provides a centralized interface for model validation, display names, and metadata retrieval.

## Key Components

**Interfaces:**
- `SupportedModel` - Model metadata including name, display name, provider, and context window
- `SupportedModelsResponse` - API response structure organized by provider

**SupportedModelsService Class:**
- `loadSupportedModels()` - Fetches and caches models from the API with promise deduplication
- `getModelDisplayName()` - Returns human-readable name for a model
- `getModel()` - Retrieves full model metadata
- `getAllModels()` - Returns array of all cached models
- `isModelSupported()` - Validates if a model is available
- `reset()` - Clears cache and state

**Export:**
- `supportedModelsService` - Singleton instance for global use

## Usage Example

```typescript
import { supportedModelsService } from './supportedModelsService'

// Load models before using
await supportedModelsService.loadSupportedModels()

// Check if model is supported
if (supportedModelsService.isModelSupported('gpt-4')) {
  console.log('Model is available')
}

// Get display name for UI
const displayName = supportedModelsService.getModelDisplayName('claude-3-opus-20240229')
// Returns: "Claude 3 Opus" instead of raw model name

// Get full model details
const model = supportedModelsService.getModel('gpt-4')
console.log(`Context window: ${model?.contextWindow}`)

// Get all models for dropdown
const allModels = supportedModelsService.getAllModels()
```

The service implements caching and prevents duplicate API calls through promise deduplication, making it efficient for repeated usage across the application.